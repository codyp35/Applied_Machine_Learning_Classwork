{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54556,
     "status": "ok",
     "timestamp": 1542734926148,
     "user": {
      "displayName": "Nelson Griffiths",
      "photoUrl": "https://lh6.googleusercontent.com/-c1Sc9zAUPoI/AAAAAAAAAAI/AAAAAAAAJQo/v1brPV7-xFQ/s64/photo.jpg",
      "userId": "06597238295245466084"
     },
     "user_tz": 420
    },
    "id": "ulbjbflquRGH",
    "outputId": "cae8540d-da35-423b-e003-500926ebedaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1073750016 bytes == 0x590c4000 @  0x7f9664f162a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n",
      "--2018-11-20 17:28:35--  https://developer.nvidia.com/compute/cuda/9.2/Prod2/local_installers/cuda-repo-ubuntu1710-9-2-local_9.2.148-1_amd64\n",
      "Resolving developer.nvidia.com (developer.nvidia.com)... 192.229.162.216\n",
      "Connecting to developer.nvidia.com (developer.nvidia.com)|192.229.162.216|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://developer.download.nvidia.com/compute/cuda/9.2/secure/Prod2/local_installers/cuda-repo-ubuntu1710-9-2-local_9.2.148-1_amd64.deb?0c5SrHAiYUYphtt9arhuLdexS3bV7cOMwPj3ik1lA_4W3ZCAB6IQY1brnmHWZWInvIfRcFXunLH_du_1aHBounyojF0jjGrLsi4IIKf_8T2ZGJhj9NbRq_5IJTO5E5j48YQ_sRWYrwGZUeR5F1IzSbbC_NetawYG__htJjXDhVaq-0Y0dYCxK9bRLSNyyVLmbLkHOAatFsZFp8EgPjkAtg [following]\n",
      "--2018-11-20 17:28:35--  https://developer.download.nvidia.com/compute/cuda/9.2/secure/Prod2/local_installers/cuda-repo-ubuntu1710-9-2-local_9.2.148-1_amd64.deb?0c5SrHAiYUYphtt9arhuLdexS3bV7cOMwPj3ik1lA_4W3ZCAB6IQY1brnmHWZWInvIfRcFXunLH_du_1aHBounyojF0jjGrLsi4IIKf_8T2ZGJhj9NbRq_5IJTO5E5j48YQ_sRWYrwGZUeR5F1IzSbbC_NetawYG__htJjXDhVaq-0Y0dYCxK9bRLSNyyVLmbLkHOAatFsZFp8EgPjkAtg\n",
      "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 192.229.211.70, 2606:2800:21f:3aa:dcf:37b:1ed6:1fb\n",
      "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|192.229.211.70|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1268794766 (1.2G) [application/x-deb]\n",
      "Saving to: ‘cuda-repo-ubuntu1710-9-2-local_9.2.148-1_amd64’\n",
      "\n",
      "cuda-repo-ubuntu171 100%[===================>]   1.18G   158MB/s    in 8.7s    \n",
      "\n",
      "2018-11-20 17:28:44 (138 MB/s) - ‘cuda-repo-ubuntu1710-9-2-local_9.2.148-1_amd64’ saved [1268794766/1268794766]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch\n",
    "\n",
    "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod2/local_installers/cuda-repo-ubuntu1710-9-2-local_9.2.148-1_amd64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49ppOo3cuJoH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import time\n",
    "import pickle\n",
    "from google.colab import files\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHkC3qEHuJoQ"
   },
   "outputs": [],
   "source": [
    "with open(r'tweets.txt', encoding = 'utf8') as f:\n",
    "    tweets = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PaWRqAwgZu12"
   },
   "outputs": [],
   "source": [
    "with open(r'New_Testament.txt', encoding = 'utf8') as f:\n",
    "    bible = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HjozUuIYuJoU"
   },
   "outputs": [],
   "source": [
    "with open(r'tweets.txt') as f:\n",
    "    tweet_content=list(set(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-1DTSoabuJoX"
   },
   "outputs": [],
   "source": [
    "#char_to_ix = {char:ix for ix, char in enumerate(tweet_content)}\n",
    "#char_to_ix[','] = 166\n",
    "\n",
    "#ix_to_char = {y:x for x,y in char_to_ix.items()}\n",
    "#vocab_size = len(ix_to_char)\n",
    "#vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0kT8S6meS7x"
   },
   "outputs": [],
   "source": [
    "#Uncomment to save mapping\n",
    "#pickle.dump(ix_to_char, open('ix_to_char_gospels.pkl', 'wb'))\n",
    "#pickle.dump(char_to_ix, open('char_to_ix_gospels.pkl', 'wb'))\n",
    "#files.download('ix_to_char_gospels.pkl')\n",
    "#files.download('char_to_ix_gospels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MG_kSzlSuJob"
   },
   "outputs": [],
   "source": [
    "tweets = tweets[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v7GxAeRzuJof"
   },
   "outputs": [],
   "source": [
    "def prepare_tweet(tweet, target = False):\n",
    "    if target==True:\n",
    "        tweet_ix = torch.cuda.LongTensor([char_to_ix[c] for c in tweet[1:]], device=device)\n",
    "        tweet_ix = tweet_ix.view(-1)\n",
    "    else:\n",
    "        tweet_ix = torch.cuda.LongTensor([char_to_ix[c] for c in tweet[:-1]], device=device)\n",
    "        tweet_ix = tweet_ix.view(-1)\n",
    "    return tweet_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4ww7Hc_uJoi"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, vocab_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers = n_layers)\n",
    "        \n",
    "        self.hidden2char = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return(torch.zeros(self.n_layers, 1, self.hidden_dim, dtype=torch.float, device = device),\n",
    "              torch.zeros(self.n_layers, 1, self.hidden_dim, dtype=torch.float, device = device))\n",
    "    \n",
    "    def forward(self, tweet):\n",
    "        embeds = self.embed(tweet)\n",
    "        lstm_out, self.hidden = self.lstm(embeds.view(len(tweet), 1, -1),\n",
    "                                         self.hidden)\n",
    "        output = F.relu(self.hidden2char(lstm_out.view(len(tweet), -1)))\n",
    "        output = self.dropout(output)\n",
    "        log_probs = F.log_softmax(output, dim=1)\n",
    "        return log_probs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bu94qBtRuJom"
   },
   "outputs": [],
   "source": [
    "def train(tweets, model, loss_function, optimizer, epochs):\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        total_loss = 0\n",
    "        for tweet in tweets:\n",
    "            model.zero_grad()\n",
    "        \n",
    "            model.hidden = model.init_hidden()\n",
    "          \n",
    "            tweet_x = prepare_tweet(tweet)\n",
    "            tweet_y = prepare_tweet(tweet, target=True)\n",
    "        \n",
    "            log_probs = model(tweet_x)\n",
    "        \n",
    "            loss = loss_function(log_probs, tweet_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        print('Epoch', epoch+1, 'Completed in %.0f' %(time.time()-epoch_start),'seconds - Loss: %.2f' %total_loss)\n",
    "    total_time = time.time() - start\n",
    "    hours = math.floor(total_time/3600)\n",
    "    minutes = total_time-(hours*3600)\n",
    "    minutes = math.floor(minutes/60)\n",
    "    seconds = total_time - (hours*3600 + minutes*60)\n",
    "    seconds = math.floor(seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K2XYfxG3uJox"
   },
   "outputs": [],
   "source": [
    "hidden_dim = 256\n",
    "embed_size = 256\n",
    "epochs = 50\n",
    "\n",
    "ix_to_char = pickle.load(open('ix_to_char_gospels (1).pkl', 'rb'))\n",
    "char_to_ix = pickle.load(open('char_to_ix_gospels (1).pkl', 'rb'))\n",
    "vocab_size = len(char_to_ix)\n",
    "\n",
    "model = RNN(embed_size, hidden_dim, vocab_size, n_layers = 3)\n",
    "model = model.cuda()\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=.0001)\n",
    "\n",
    "checkpoint = torch.load('trump_gospel1.tar')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25480566,
     "status": "error",
     "timestamp": 1542451164346,
     "user": {
      "displayName": "Nelson Griffiths",
      "photoUrl": "https://lh6.googleusercontent.com/-c1Sc9zAUPoI/AAAAAAAAAAI/AAAAAAAAJQo/v1brPV7-xFQ/s64/photo.jpg",
      "userId": "06597238295245466084"
     },
     "user_tz": 420
    },
    "id": "qINhqb-ruJo1",
    "outputId": "fe5f41df-c60f-4768-8d70-6728ca2f761d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Completed in 176 seconds - Loss: 20416.70\n",
      "Epoch 2 Completed in 175 seconds - Loss: 20326.58\n",
      "Epoch 3 Completed in 175 seconds - Loss: 20236.93\n",
      "Epoch 4 Completed in 177 seconds - Loss: 20147.08\n",
      "Epoch 5 Completed in 180 seconds - Loss: 20056.50\n",
      "Epoch 6 Completed in 181 seconds - Loss: 19965.17\n",
      "Epoch 7 Completed in 181 seconds - Loss: 19873.12\n",
      "Epoch 8 Completed in 177 seconds - Loss: 19776.66\n",
      "Epoch 9 Completed in 177 seconds - Loss: 19672.21\n",
      "Epoch 10 Completed in 180 seconds - Loss: 19566.30\n",
      "Epoch 11 Completed in 181 seconds - Loss: 19454.07\n",
      "Epoch 12 Completed in 178 seconds - Loss: 19332.78\n",
      "Epoch 13 Completed in 179 seconds - Loss: 19213.85\n",
      "Epoch 14 Completed in 179 seconds - Loss: 19082.31\n",
      "Epoch 15 Completed in 181 seconds - Loss: 18937.70\n",
      "Epoch 16 Completed in 176 seconds - Loss: 18782.05\n",
      "Epoch 17 Completed in 179 seconds - Loss: 18629.55\n",
      "Epoch 18 Completed in 181 seconds - Loss: 18464.74\n",
      "Epoch 19 Completed in 181 seconds - Loss: 18317.62\n",
      "Epoch 20 Completed in 187 seconds - Loss: 18151.32\n",
      "Epoch 21 Completed in 178 seconds - Loss: 18023.08\n",
      "Epoch 22 Completed in 179 seconds - Loss: 17901.99\n",
      "Epoch 23 Completed in 181 seconds - Loss: 17790.07\n",
      "Epoch 24 Completed in 184 seconds - Loss: 17704.15\n",
      "Epoch 25 Completed in 178 seconds - Loss: 17622.03\n",
      "Epoch 26 Completed in 179 seconds - Loss: 17556.85\n",
      "Epoch 27 Completed in 179 seconds - Loss: 17492.16\n",
      "Epoch 28 Completed in 179 seconds - Loss: 17451.78\n",
      "Epoch 29 Completed in 179 seconds - Loss: 17420.52\n",
      "Epoch 30 Completed in 179 seconds - Loss: 17389.07\n",
      "Epoch 31 Completed in 179 seconds - Loss: 17371.94\n",
      "Epoch 32 Completed in 179 seconds - Loss: 17356.79\n",
      "Epoch 33 Completed in 179 seconds - Loss: 17335.08\n",
      "Epoch 34 Completed in 179 seconds - Loss: 17325.36\n",
      "Epoch 35 Completed in 179 seconds - Loss: 17317.32\n",
      "Epoch 36 Completed in 179 seconds - Loss: 17306.15\n",
      "Epoch 37 Completed in 177 seconds - Loss: 17298.03\n",
      "Epoch 38 Completed in 176 seconds - Loss: 17289.49\n",
      "Epoch 39 Completed in 176 seconds - Loss: 17279.82\n",
      "Epoch 40 Completed in 176 seconds - Loss: 17255.09\n",
      "Epoch 41 Completed in 176 seconds - Loss: 17264.30\n",
      "Epoch 42 Completed in 177 seconds - Loss: 17263.75\n",
      "Epoch 43 Completed in 176 seconds - Loss: 17266.64\n",
      "Epoch 44 Completed in 176 seconds - Loss: 17258.67\n"
     ]
    }
   ],
   "source": [
    "train(tweets, model, loss_function, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7394539,
     "status": "ok",
     "timestamp": 1542694185139,
     "user": {
      "displayName": "Nelson Griffiths",
      "photoUrl": "https://lh6.googleusercontent.com/-c1Sc9zAUPoI/AAAAAAAAAAI/AAAAAAAAJQo/v1brPV7-xFQ/s64/photo.jpg",
      "userId": "06597238295245466084"
     },
     "user_tz": 420
    },
    "id": "UnQ9XYf_qWuD",
    "outputId": "c2a977a7-a9e9-4b95-c26f-d8a3fff30120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Downloaded\n"
     ]
    }
   ],
   "source": [
    "print('Saving Model...')\n",
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, 'trump_gospel1.tar')\n",
    "print('Downloading Saved Model...')\n",
    "files.download('trump_gospel1.tar')\n",
    "print('Model Downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdkHpHZ1uJos"
   },
   "outputs": [],
   "source": [
    "def generate_tweet(inputs, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        char = torch.LongTensor([char_to_ix[c] for c in inputs], device=device)\n",
    "        char = char.cuda()\n",
    "        model.hidden = model.init_hidden()\n",
    "        output_tweet = inputs\n",
    "        letter = inputs\n",
    "    \n",
    "        for i in range(280):\n",
    "            model.hidden = model.init_hidden()\n",
    "            char = char.view(-1)\n",
    "            output = model(char)\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0].item()\n",
    "            letter = ix_to_char[topi]\n",
    "            print(letter)\n",
    "            if letter == '\\n':\n",
    "                break\n",
    "            else:    \n",
    "                output_tweet += letter\n",
    "                char = torch.LongTensor(char_to_ix[letter], device=device)\n",
    "                char = char.cuda()\n",
    "    return output_tweet"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "The Book of Trump - Data Prep.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
